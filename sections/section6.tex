\section{Use Cases of TensorFlow Today}\label{sec:uses}

In this section, we investigate where TensorFlow is already in use today. Given
that TensorFlow was released only little over 6 months ago as of this writing,
its adoption in academia and industry is not yet widespread. The one exception
is, of course, Google, which has already deployed TensorFlow for a variety of
learning tasks \cite{phones, emails, drugs, inception}.

In \cite{drugs}, Ramsundar et al. discuss massively ``multitask networks for
drug discovery'' in a joint collaboration work between Stanford University and
Google, published in early 2016. In this paper, the authors employ deep neural
networks developed with TensorFlow to perform virtual screening of potential
drug candidates. This is intended to aid pharmaceutical companies and the
scientific community in finding novel medication and treatments for human
diseases.

August and Ni apply TensorFlow to create recurrent neural networks for
optimizing dynamic decoupling, a technique for suppressing errors in quantum
memory \cite{august}. With this, the authors aim to preserve the coherence of
quantum states, which is one of the primary requirements for building universal
quantum computers.

Lastly, we make note of the decision of Google DeepMind, an AI division within
Google, to move from Torch7 to TensorFlow \cite{deepmind}. A related source,
\cite{tpu}, states that DeepMind made use of TensorFlow for its
\emph{AlphaGo}\footnote{https://deepmind.com/alpha-go} model, alongside Google's
newly developed Tensor Processing Unit (TPU), which was built to integrate
especially well with TensorFlow. In a correspondence of the authors of this
paper with a member of the Google DeepMind team, the following four reasons were
revealed to us as to why TensorFlow is advantageous to DeepMind:

\begin{enumerate}
\item TensorFlow is included in the Google Cloud
  Platform\footnote{https://cloud.google.com/compute/}, which enables easy
  replication of DeepMind's research.
\item TensorFlow's support for TPUs.
\item TensorFlow's main interface, Python, is one of the core languages at
  Google, which implies a much greater internal tool set than for Lua.
\item The ability to run TensorFlow on many GPUs.
\end{enumerate}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End: